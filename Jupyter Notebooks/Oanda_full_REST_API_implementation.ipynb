{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries and set up the rate limiter\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import configparser\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, max_per_second):\n",
    "        self.max_per_second = max_per_second\n",
    "        self.last_called = 0\n",
    "\n",
    "    def __call__(self, func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            elapsed = time.time() - self.last_called\n",
    "            left_to_wait = 1 / self.max_per_second - elapsed\n",
    "            if left_to_wait > 0:\n",
    "                time.sleep(left_to_wait)\n",
    "            self.last_called = time.time()\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "rate_limiter = RateLimiter(max_per_second=2)  # Limit to 2 requests per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define the OandaDataFetcher class\n",
    "class OandaDataFetcher:\n",
    "    def __init__(self, api_key, account_id):\n",
    "        self.api_key = api_key\n",
    "        self.account_id = account_id\n",
    "        self.base_url = \"https://api-fxpractice.oanda.com/v3\"  # Use api-fxtrade for live accounts\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "    @rate_limiter\n",
    "    def fetch_candles(self, instrument, granularity, count=None, from_time=None, to_time=None):\n",
    "        endpoint = f\"{self.base_url}/instruments/{instrument}/candles\"\n",
    "        params = {\n",
    "            \"granularity\": granularity,\n",
    "            \"price\": \"M\"  # Midpoint candles\n",
    "        }\n",
    "        if count:\n",
    "            params[\"count\"] = count\n",
    "        if from_time:\n",
    "            params[\"from\"] = from_time.isoformat(\"T\") + \"Z\"\n",
    "        if to_time:\n",
    "            params[\"to\"] = to_time.isoformat(\"T\") + \"Z\"\n",
    "\n",
    "        response = requests.get(endpoint, headers=self.headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def fetch_historical_data(self, instrument, granularity, count=1000):\n",
    "        data = self.fetch_candles(instrument, granularity, count=count)\n",
    "        return self._parse_candle_data(data, instrument, granularity)\n",
    "\n",
    "    def _parse_candle_data(self, data, instrument, granularity):\n",
    "        candles = data['candles']\n",
    "        parsed_data = []\n",
    "        for candle in candles:\n",
    "            parsed_data.append({\n",
    "                'timestamp': pd.to_datetime(candle['time']),\n",
    "                'open': float(candle['mid']['o']),\n",
    "                'high': float(candle['mid']['h']),\n",
    "                'low': float(candle['mid']['l']),\n",
    "                'close': float(candle['mid']['c']),\n",
    "                'volume': int(candle['volume']),\n",
    "                'symbol': instrument,\n",
    "                'timeframe': granularity\n",
    "            })\n",
    "        return pd.DataFrame(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Set up configuration and initialize OandaDataFetcher\n",
    "# Load the credentials from oanda.cfg\n",
    "config = configparser.ConfigParser()\n",
    "config.read('oanda.cfg')\n",
    "\n",
    "# Extract details from the configuration file\n",
    "OANDA_ACCOUNT_ID = config['oanda']['account_id']\n",
    "OANDA_API_KEY = config['oanda']['access_token']\n",
    "\n",
    "# Initialize the OANDA data fetcher\n",
    "fetcher = OandaDataFetcher(OANDA_API_KEY, OANDA_ACCOUNT_ID)\n",
    "\n",
    "# Load symbols from symbols.txt\n",
    "with open('symbols.txt', 'r') as f:\n",
    "    symbols = [line.strip() for line in f]\n",
    "\n",
    "# Define timeframes\n",
    "timeframes = ['H1', 'H4', 'H8', 'H12', 'D', 'W', 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 4: Set up TimescaleDB connection and create tables\n",
    "def create_timescale_connection():\n",
    "    return psycopg2.connect(\n",
    "        dbname=\"forex_data\",\n",
    "        user=\"your_username\",\n",
    "        password=\"your_password\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "def create_tables():\n",
    "    conn = create_timescale_connection()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Create price_data table\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS price_data (\n",
    "        symbol TEXT NOT NULL,\n",
    "        timestamp TIMESTAMPTZ NOT NULL,\n",
    "        timeframe TEXT NOT NULL,\n",
    "        open DOUBLE PRECISION,\n",
    "        high DOUBLE PRECISION,\n",
    "        low DOUBLE PRECISION,\n",
    "        close DOUBLE PRECISION,\n",
    "        volume INTEGER\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    # Convert to hypertable\n",
    "    cur.execute(\"SELECT create_hypertable('price_data', 'timestamp', if_not_exists => TRUE);\")\n",
    "    \n",
    "    # Create index\n",
    "    cur.execute(\"CREATE INDEX IF NOT EXISTS idx_price_data ON price_data (symbol, timeframe, timestamp DESC);\")\n",
    "    \n",
    "    # Create critical_indicators table\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS critical_indicators (\n",
    "        symbol TEXT NOT NULL,\n",
    "        timestamp TIMESTAMPTZ NOT NULL,\n",
    "        timeframe TEXT NOT NULL,\n",
    "        indicator_name TEXT NOT NULL,\n",
    "        value DOUBLE PRECISION\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    # Convert to hypertable\n",
    "    cur.execute(\"SELECT create_hypertable('critical_indicators', 'timestamp', if_not_exists => TRUE);\")\n",
    "    \n",
    "    # Create index\n",
    "    cur.execute(\"CREATE INDEX IF NOT EXISTS idx_critical_indicators ON critical_indicators (symbol, timeframe, indicator_name, timestamp DESC);\")\n",
    "    \n",
    "    # Create trading_signals table\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS trading_signals (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        symbol TEXT NOT NULL,\n",
    "        timestamp TIMESTAMPTZ NOT NULL,\n",
    "        timeframe TEXT NOT NULL,\n",
    "        signal_type TEXT NOT NULL,\n",
    "        entry_price DOUBLE PRECISION,\n",
    "        stop_loss DOUBLE PRECISION,\n",
    "        target1 DOUBLE PRECISION,\n",
    "        target2 DOUBLE PRECISION,\n",
    "        target3 DOUBLE PRECISION\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create index\n",
    "    cur.execute(\"CREATE INDEX IF NOT EXISTS idx_trading_signals ON trading_signals (symbol, timeframe, timestamp DESC);\")\n",
    "    \n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "create_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define functions for database operations\n",
    "def insert_price_data(df):\n",
    "    conn = create_timescale_connection()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        cur.execute(\"\"\"\n",
    "        INSERT INTO price_data (symbol, timestamp, timeframe, open, high, low, close, volume)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (symbol, timestamp, timeframe) DO UPDATE\n",
    "        SET open = EXCLUDED.open, high = EXCLUDED.high, low = EXCLUDED.low, close = EXCLUDED.close, volume = EXCLUDED.volume\n",
    "        \"\"\", (row['symbol'], row['timestamp'], row['timeframe'], row['open'], row['high'], row['low'], row['close'], row['volume']))\n",
    "    \n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "def insert_critical_indicator(symbol, timestamp, timeframe, indicator_name, value):\n",
    "    conn = create_timescale_connection()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "    INSERT INTO critical_indicators (symbol, timestamp, timeframe, indicator_name, value)\n",
    "    VALUES (%s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (symbol, timestamp, timeframe, indicator_name) DO UPDATE\n",
    "    SET value = EXCLUDED.value\n",
    "    \"\"\", (symbol, timestamp, timeframe, indicator_name, value))\n",
    "    \n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "def insert_trading_signal(symbol, timestamp, timeframe, signal_type, entry_price, stop_loss, target1, target2, target3):\n",
    "    conn = create_timescale_connection()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "    INSERT INTO trading_signals (symbol, timestamp, timeframe, signal_type, entry_price, stop_loss, target1, target2, target3)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (symbol, timestamp, timeframe, signal_type, entry_price, stop_loss, target1, target2, target3))\n",
    "    \n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "def get_existing_data_count(symbol, timeframe):\n",
    "    conn = create_timescale_connection()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "    SELECT COUNT(*) FROM price_data\n",
    "    WHERE symbol = %s AND timeframe = %s\n",
    "    \"\"\", (symbol, timeframe))\n",
    "    \n",
    "    count = cur.fetchone()[0]\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Fetch and store data for all symbols and timeframes\n",
    "def calculate_critical_indicators(df):\n",
    "    # Calculate SMA20\n",
    "    df['SMA20'] = df['close'].rolling(window=20).mean()\n",
    "    \n",
    "    # Calculate MACD\n",
    "    exp1 = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = exp1 - exp2\n",
    "    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    # Calculate ATR\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = np.abs(df['high'] - df['close'].shift())\n",
    "    low_close = np.abs(df['low'] - df['close'].shift())\n",
    "    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "    true_range = np.max(ranges, axis=1)\n",
    "    df['ATR'] = true_range.rolling(window=14).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fetch_and_store_data(symbol, timeframe):\n",
    "    existing_count = get_existing_data_count(symbol, timeframe)\n",
    "    if existing_count < 1000:\n",
    "        print(f\"Fetching data for {symbol} - {timeframe}\")\n",
    "        data = fetcher.fetch_historical_data(symbol, timeframe, count=1000)\n",
    "        insert_price_data(data)\n",
    "        \n",
    "        # Calculate and store critical indicators\n",
    "        data_with_indicators = calculate_critical_indicators(data)\n",
    "        for _, row in data_with_indicators.iterrows():\n",
    "            insert_critical_indicator(symbol, row['timestamp'], timeframe, 'SMA20', row['SMA20'])\n",
    "            insert_critical_indicator(symbol, row['timestamp'], timeframe, 'MACD', row['MACD'])\n",
    "            insert_critical_indicator(symbol, row['timestamp'], timeframe, 'Signal_Line', row['Signal_Line'])\n",
    "            insert_critical_indicator(symbol, row['timestamp'], timeframe, 'ATR', row['ATR'])\n",
    "        \n",
    "        print(f\"Stored {len(data)} candles and indicators for {symbol} - {timeframe}\")\n",
    "    else:\n",
    "        print(f\"Sufficient data already exists for {symbol} - {timeframe}\")\n",
    "\n",
    "# Fetch and store data for all symbols and timeframes\n",
    "for symbol in symbols:\n",
    "    for timeframe in timeframes:\n",
    "        fetch_and_store_data(symbol, timeframe)\n",
    "        time.sleep(1)  # Additional delay to be extra cautious with API rate limits\n",
    "\n",
    "print(\"Data fetching and storage complete for all symbols and timeframes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Query and display stored data\n",
    "def query_data_with_indicators(symbol, timeframe, limit=10):\n",
    "    conn = create_timescale_connection()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "    SELECT p.*, \n",
    "           i1.value as SMA20, \n",
    "           i2.value as MACD, \n",
    "           i3.value as Signal_Line, \n",
    "           i4.value as ATR\n",
    "    FROM price_data p\n",
    "    LEFT JOIN critical_indicators i1 ON p.symbol = i1.symbol AND p.timestamp = i1.timestamp AND p.timeframe = i1.timeframe AND i1.indicator_name = 'SMA20'\n",
    "    LEFT JOIN critical_indicators i2 ON p.symbol = i2.symbol AND p.timestamp = i2.timestamp AND p.timeframe = i2.timeframe AND i2.indicator_name = 'MACD'\n",
    "    LEFT JOIN critical_indicators i3 ON p.symbol = i3.symbol AND p.timestamp = i3.timestamp AND p.timeframe = i3.timeframe AND i3.indicator_name = 'Signal_Line'\n",
    "    LEFT JOIN critical_indicators i4 ON p.symbol = i4.symbol AND p.timestamp = i4.timestamp AND p.timeframe = i4.timeframe AND i4.indicator_name = 'ATR'\n",
    "    WHERE p.symbol = %s AND p.timeframe = %s\n",
    "    ORDER BY p.timestamp DESC\n",
    "    LIMIT %s\n",
    "    \"\"\", (symbol, timeframe, limit))\n",
    "    \n",
    "    columns = [desc[0] for desc in cur.description]\n",
    "    result = cur.fetchall()\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return pd.DataFrame(result, columns=columns)\n",
    "\n",
    "# Example usage\n",
    "result = query_data_with_indicators(symbols[0], 'H1', limit=5)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Implement a simple moving average calculation\n",
    "def calculate_experimental_indicator(df):\n",
    "    # This is just an example. Replace with your actual experimental indicator calculation\n",
    "    df['Experimental'] = (df['high'] + df['low']) / 2 * df['volume']\n",
    "    return df\n",
    "\n",
    "def get_data_with_all_indicators(symbol, timeframe, limit=1000):\n",
    "    # Fetch data with critical indicators from the database\n",
    "    df = query_data_with_indicators(symbol, timeframe, limit)\n",
    "    \n",
    "    # Calculate experimental indicators on the fly\n",
    "    df = calculate_experimental_indicator(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "result = get_data_with_all_indicators(symbols[0], 'H1', limit=100)\n",
    "display(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of each step:\n",
    "1. Installation: We install TimescaleDB, PostgreSQL, and necessary Python packages.\n",
    "2. Database setup: We create a new database and enable the TimescaleDB extension.\n",
    "3. Jupyter notebook: We create a new notebook for our forex data analysis.\n",
    "4. Cell 1: We import necessary libraries and set up a rate limiter to respect API limits.\n",
    "5. Cell 2: We define the OandaDataFetcher class to interact with the OANDA API.\n",
    "6. Cell 3: We load configuration, initialize the data fetcher, and load symbols from symbols.txt.\n",
    "7. Cell 4: We set up the TimescaleDB connection and create the necessary table.\n",
    "8. Cell 5: We define functions for database operations, including inserting data and checking existing data.\n",
    "9. Cell 6: We fetch and store data for all symbols and timeframes, ensuring we have 1000 bars for each.\n",
    "10. Cell 7: We implement a function to query and display stored data.\n",
    "11. Cell 8: We implement a simple moving average calculation as an example of data analysis.\n",
    "This implementation ensures that:\n",
    "- We use TimescaleDB for efficient time-series data storage.\n",
    "- We fetch data for all symbols listed in symbols.txt.\n",
    "- We create and populate tables for all specified timeframes.\n",
    "- We check if a table already exists and has the full complement of price bars before fetching new data.\n",
    "We use proper indexing for faster queries.\n",
    "Remember to replace 'your_username' and 'your_password' in the create_timescale_connection function with your actual PostgreSQL credentials. Also, ensure that your oanda.cfg file is in the same directory as your Jupyter notebook and contains your OANDA account ID and API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regarding OANDA's rate limits:\n",
    "OANDA's API has rate limits, but they are quite generous for most use cases. As of my last update, the limits were:\n",
    "1. 120 requests per second\n",
    "2. 24000 requests per minute (for practice accounts)\n",
    "3. 10000 requests per minute (for live accounts)\n",
    "The code as written is unlikely to violate these rate limits for a single instrument. However, if you're fetching data for many instruments simultaneously or very frequently, you should implement rate limiting in your code.\n",
    "To stay well within the limits and be a good API citizen, you could implement a simple rate limiter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements:\n",
    "1. for the initialisation of the system, I could populate the higher timeframe databases by requesting 4H, 8H and 12H bars, and subsequently build the higher timeframes from the 1H bars.\n",
    "2. I also have a complex strategy which uses 8 moving average, macd, and art indicators, to derive trading signals, with each signal having entry, stop targets 1, 2 & 3 defined, and I want to retain a history of when these signals occurred, so that I can plot the data on a candlestick chart, together with the indicators. I can use a technical analysis library for the indicator values, if necessary, but what would you recommend, should I store and calculate values in pandas or store them with price data in the databases. Remember I will have multiple databases for each of my symbols. \n",
    "\n",
    "Before creating anything explain how you would do this and what would you recommend for the database structure, and should this be something more substantial than SQLite, (Postgres or Timescale DB, whatever used must be FREE). Explain the database schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oanda Full REST API Implementation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Jupyter notebook implements a comprehensive forex data analysis system using the Oanda REST API and TimescaleDB. The system is designed to fetch, store, and analyze forex data for multiple currency pairs and timeframes.\n",
    "\n",
    "File: `h:\\My Drive\\00 PROJECTS\\0.3 Coding\\TradingBot\\Jupyter Notebooks\\Oanda_full_REST_API_implementation.ipynb`\n",
    "\n",
    "## Database Choice: TimescaleDB\n",
    "\n",
    "We've chosen TimescaleDB for this implementation due to its:\n",
    "- Optimization for time-series data\n",
    "- Scalability for handling large datasets\n",
    "- Compatibility with PostgreSQL\n",
    "- Free and open-source nature\n",
    "\n",
    "TimescaleDB excels at fast data inserts and complex queries, making it ideal for our forex data analysis system.\n",
    "\n",
    "## System Design\n",
    "\n",
    "Our implementation covers four key areas:\n",
    "\n",
    "1. **Initial Data Population**: Fetching historical data for all currency pairs and timeframes.\n",
    "2. **Ongoing Data Collection**: Regular updates to keep our database current.\n",
    "3. **Signal Generation and Storage**: Calculating indicators and generating trading signals.\n",
    "4. **Data Retrieval and Analysis**: Efficient querying for analysis and visualization.\n",
    "\n",
    "This notebook provides a solid foundation for building a robust forex trading and analysis system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Steps\n",
    "\n",
    "1. **Set up TimescaleDB**\n",
    "   - Install PostgreSQL and TimescaleDB extension\n",
    "   - Create a new database named 'forex_data'\n",
    "\n",
    "2. **Set up Python Environment**\n",
    "   - Install required libraries: psycopg2, pandas, requests, numpy\n",
    "\n",
    "3. **Implement Core Functionality**\n",
    "   - RateLimiter: Manage API request frequency\n",
    "   - OandaDataFetcher: Fetch data from Oanda API\n",
    "   - Database operations: Connection, table creation, data insertion, and querying\n",
    "\n",
    "4. **Create Database Schema**\n",
    "   - Execute SQL commands to create necessary tables:\n",
    "     - price_data\n",
    "     - critical_indicators\n",
    "     - trading_signals\n",
    "\n",
    "5. **Initial Data Population**\n",
    "   - Fetch historical data for all symbols and timeframes\n",
    "   - Calculate and store critical indicators\n",
    "\n",
    "6. **Implement Data Analysis Functions**\n",
    "   - Query data with indicators\n",
    "   - Calculate experimental indicators on-the-fly\n",
    "\n",
    "7. **Future Considerations**\n",
    "   - Implement SignalGenerator for trading signals\n",
    "   - Set up scheduled job for regular data updates (e.g., using cron or Windows Task Scheduler)\n",
    "\n",
    "## Database Structure\n",
    "\n",
    "1. **price_data Table (Hypertable)**\n",
    "   - Stores price data for all symbols and timeframes\n",
    "   - Columns:\n",
    "     - symbol: The currency pair (e.g., 'EUR_USD')\n",
    "     - timestamp: The exact time of the price data point\n",
    "     - timeframe: The candlestick timeframe (e.g., 'H1', 'H4', 'D')\n",
    "     - open, high, low, close: Price data\n",
    "     - volume: Trading volume\n",
    "\n",
    "2. **critical_indicators Table (Hypertable)**\n",
    "   - Stores pre-calculated indicator values\n",
    "   - Columns:\n",
    "     - symbol: The currency pair\n",
    "     - timestamp: The time of the indicator value\n",
    "     - timeframe: The candlestick timeframe\n",
    "     - indicator_name: Name of the indicator (e.g., 'SMA20', 'MACD')\n",
    "     - value: The calculated indicator value\n",
    "\n",
    "3. **trading_signals Table**\n",
    "   - Stores generated trading signals\n",
    "   - Columns:\n",
    "     - symbol: The currency pair\n",
    "     - timestamp: The time of the signal\n",
    "     - timeframe: The candlestick timeframe\n",
    "     - signal_type: Type of trading signal (e.g., 'BUY', 'SELL')\n",
    "     - entry_price, stop_loss, target1, target2, target3: Signal details\n",
    "\n",
    "This structure allows for efficient storage and retrieval of forex data, indicators, and signals across multiple symbols and timeframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Implementation and Coverage\n",
    "\n",
    "Our implementation uses a single TimescaleDB database to efficiently manage data for all forex symbols and timeframes. Here's an overview of the structure and coverage:\n",
    "\n",
    "### Single Database Approach\n",
    "\n",
    "We use a TimescaleDB database named 'forex_data' with three main tables:\n",
    "\n",
    "1. **price_data** (Hypertable):\n",
    "   - Stores raw price data for all symbols and timeframes\n",
    "   - Columns: symbol, timestamp, timeframe, open, high, low, close, volume\n",
    "\n",
    "2. **critical_indicators** (Hypertable):\n",
    "   - Stores pre-calculated indicator values\n",
    "   - Columns: symbol, timestamp, timeframe, indicator_name, value\n",
    "\n",
    "3. **trading_signals**:\n",
    "   - Stores generated trading signals\n",
    "   - Columns: symbol, timestamp, timeframe, signal_type, entry_price, stop_loss, target1, target2, target3\n",
    "\n",
    "Each table uses 'symbol' and 'timeframe' columns to differentiate between currency pairs and time intervals.\n",
    "\n",
    "### Coverage of All Symbols and Timeframes\n",
    "\n",
    "Our system is designed to work with:\n",
    "\n",
    "- All symbols listed in the 'symbols.txt' file\n",
    "- All specified timeframes: H1, H4, H8, H12, D, W, M\n",
    "\n",
    "The `fetch_and_store_data` function in Cell 6 ensures comprehensive data collection:\n",
    "for symbol in symbols:\n",
    "for timeframe in timeframes:\n",
    "fetch_and_store_data(symbol, timeframe)\n",
    "time.sleep(1) # Rate limiting\n",
    "\n",
    "\n",
    "This approach allows for:\n",
    "- Efficient querying across multiple symbols and timeframes\n",
    "- Easy addition of new symbols or timeframes\n",
    "- Scalable handling of large volumes of time-series data\n",
    "\n",
    "By using a single database with hypertables, we've created a flexible and powerful system for forex data analysis and strategy testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and configure TimescaleDB on PostgreSQL\n",
    "https://docs.timescale.com/self-hosted/latest/install/installation-windows/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
